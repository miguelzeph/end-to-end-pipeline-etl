version: '3.8'

services:
  # Banco de dados para metadados do Airflow
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Zookeeper para o Kafka
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  # Kafka para transmissão de dados em streaming
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    depends_on:
      - zookeeper

  # Airflow para orquestração do pipeline ETL
  airflow:
    build:
      context: .
      dockerfile: docker/Dockerfile_airflow
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    ports:
      - "8080:8080"
    volumes:
      - ./src/airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    depends_on:
      - postgres

  # Spark para processamento de dados
  spark:
    build:
      context: .
      dockerfile: docker/Dockerfile_spark
    ports:
      - "8081:8081"
    environment:
      SPARK_MASTER_WEBUI_PORT: 8081
      SPARK_MASTER_LOG_DIR: /tmp/spark/logs
    volumes:
      - spark_data:/tmp/spark/data
      - ./src/spark:/opt/spark/work-dir
    depends_on:
      - kafka

  # MongoDB para armazenamento dos dados finais
  mongodb:
    image: mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

volumes:
  postgres_data:
  airflow_logs:
  spark_data:
  mongo_data:
